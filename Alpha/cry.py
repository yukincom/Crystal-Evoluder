"""
Crystal Evoluder v1.0
Knowledge Crystallization System

"""

from bs4 import BeautifulSoup
from llama_index.core import Document, KnowledgeGraphIndex, StorageContext
from llama_index.graph_stores.neo4j import Neo4jGraphStore
from llama_index.llms.openai import OpenAI
from llama_index.core.node_parser import SimpleNodeParser
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
import os
import re
import logging
import concurrent.futures
import time
from pathlib import Path
from typing import Optional, List, Dict


class CrystalEvoluder:
    """
    Crystal Evoluder - Knowledge Crystallization System
    
    „Éá„Ç∏„Çø„É´ÊäÄË°ì„ÅÆÂü∫Áõ§„Å®„Å™„ÇãÁß©Â∫èÂåñ„Åï„Çå„ÅüÊßãÈÄ†
    - Ê∞¥Êô∂ÊåØÂãïÂ≠ê: „Éá„Ç∏„Çø„É´ÂõûË∑Ø„ÅÆÂøÉËáì
    - Ê∂≤Êô∂: ÊÉÖÂ†±„ÅÆË°®Á§∫Èù¢
    - ÁµêÊô∂ÊàêÈï∑: Áü•Ë≠ò„ÅåÁß©Â∫è„ÇíÊåÅ„Å£„Å¶Â¢óÊÆñ
    """
    
    def __init__(self, config: Optional[Dict] = None, log_level: int = logging.INFO):
        self.config = config or {}
        self.crystal = None
        self.metadata = {}
        
        # „É≠„Ç¨„ÉºË®≠ÂÆö
        self.logger = self._setup_logger(log_level)
        self.logger.info("Crystal Evoluder initialized")
    
    def _setup_logger(self, level: int) -> logging.Logger:
        """ÈöéÂ±§Âåñ„Åï„Çå„Åü„É≠„Ç¨„ÉºË®≠ÂÆö"""
        logger = logging.getLogger('CrystalEvoluder')
        logger.setLevel(level)
        
        # Êó¢Â≠ò„Éè„É≥„Éâ„É©„Çí„ÇØ„É™„Ç¢
        logger.handlers.clear()
        
        # „Ç≥„É≥„ÇΩ„Éº„É´„Éè„É≥„Éâ„É©ÔºàÂé®‰∫åÊºîÂá∫Áî®Ôºâ
        console = logging.StreamHandler()
        
        class IconFormatter(logging.Formatter):
            ICONS = {
                'DEBUG': 'üîç',
                'INFO': '‚ú®',
                'WARNING': '‚ö†Ô∏è',
                'ERROR': '‚ùå',
                'CRITICAL': 'üí•'
            }
            
            def format(self, record):
                icon = self.ICONS.get(record.levelname, '‚ÑπÔ∏è')
                record.icon = icon
                return super().format(record)
        
        console.setFormatter(IconFormatter('%(icon)s %(message)s'))
        logger.addHandler(console)
        
        # „Éï„Ç°„Ç§„É´„Éè„É≥„Éâ„É©ÔºàÁ†îÁ©∂ËÄÖÁî®Ôºâ
        log_file = Path('crystal_evoluder.log')
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        logger.addHandler(file_handler)
        
        return logger
    
    def crystallize(self, tei_path: str, strict_mode: bool = False) -> List[Document]:
        """
        üîÆ ÁµêÊô∂Âåñ: TEI„ÇíÁß©Â∫èÂåñ„Åï„Çå„ÅüÊßãÈÄ†„Å´Â§âÊèõ
        
        Args:
            tei_path: GROBID„ÅåÂá∫Âäõ„Åó„ÅüTEI„Éï„Ç°„Ç§„É´
            strict_mode: True„Å™„ÇâÂ£ä„Çå„ÅüTEI„ÅßÂÅúÊ≠¢„ÄÅFalse„Å™„ÇâÁ∂öË°å
        
        Returns:
            crystallized_documents: ÁµêÊô∂Âåñ„Åï„Çå„Åü„Éâ„Ç≠„É•„É°„É≥„Éà
        """
        self.logger.info("Crystallizing knowledge structure...")
        
        tei_path = Path(tei_path).expanduser()
        
        if not tei_path.exists():
            self.logger.error(f"TEI file not found: {tei_path}")
            raise FileNotFoundError(f"TEI file not found: {tei_path}")
        
        # TEI„Çí„Éë„Éº„Çπ
        try:
            with open(tei_path, 'r', encoding='utf-8') as f:
                soup = BeautifulSoup(f, 'xml')
            self.logger.debug(f"TEI parsed successfully: {tei_path}")
        except Exception as e:
            self.logger.error(f"Failed to parse TEI: {e}", exc_info=True)
            if strict_mode:
                raise
            return []
        
        # „É°„Çø„Éá„Éº„ÇøÊäΩÂá∫Ôºà„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ‰ªò„ÅçÔºâ
        title = self._extract_title_safe(soup, tei_path)
        authors = self._extract_authors_safe(soup)
        
        self.logger.info(f"  ‚îú‚îÄ Title: \"{title}\"")
        self.logger.info(f"  ‚îú‚îÄ Authors: {', '.join(authors[:3])}")
        
        # „Çª„ÇØ„Ç∑„Éß„É≥ÊäΩÂá∫ÔºàÂ£ä„Çå„Å¶„Å¶„ÇÇÁ∂öË°åÔºâ
        documents = []
        divs = soup.find_all('div')
        self.logger.debug(f"Found {len(divs)} div elements")
        
        for i, div in enumerate(divs):
            try:
                doc = self._extract_section_safe(div, i, title, authors)
                if doc:
                    documents.append(doc)
                    self.logger.debug(f"Section {i} extracted: {doc.metadata['section']}")
            except Exception as e:
                self.logger.warning(f"Skipping broken section {i}: {e}")
                if strict_mode:
                    raise
                continue
        
        # Ê§úË®º
        if len(documents) == 0:
            self.logger.error("No valid sections found in TEI")
            if strict_mode:
                raise ValueError("TEI completely broken - no sections extracted")
        
        self.logger.info(f"  ‚îú‚îÄ Sections: {len(documents)} fragments detected")
        self.logger.info(f"  ‚îî‚îÄ Crystal formed: {len(documents)} nodes")
        self.logger.info("‚ú® Crystal structure stabilized")
        
        self.crystal = documents
        self.metadata = {'title': title, 'authors': authors}
        
        return documents
    
    def _extract_title_safe(self, soup: BeautifulSoup, filepath: Path) -> str:
        """„Çø„Ç§„Éà„É´ÊäΩÂá∫Ôºà„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ‰ªò„ÅçÔºâ"""
        try:
            title_tag = soup.find('titleStmt')
            if title_tag:
                title_tag = title_tag.find('title', level='a', type='main')
            title = title_tag.text.strip() if title_tag else None
            
            if title and len(title) > 10:
                return title
        except Exception as e:
            self.logger.debug(f"Title extraction failed: {e}")
        
        # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ1: „Éï„Ç°„Ç§„É´Âêç„Åã„ÇâÊé®Ê∏¨
        self.logger.warning("Title not found in TEI, using filename")
        return filepath.stem.replace('_', ' ').replace('.tei', '').title()
    
    def _extract_authors_safe(self, soup: BeautifulSoup) -> List[str]:
        """ËëóËÄÖÊäΩÂá∫Ôºà„Ç®„É©„ÉºËÄêÊÄßÔºâ"""
        authors = []
        try:
            for persName in soup.find_all('persName'):
                try:
                    forenames = [f.text for f in persName.find_all('forename') if f.text]
                    surname = persName.find('surname')
                    author_name = f"{' '.join(forenames)} {surname.text if surname else ''}".strip()
                    if author_name and len(author_name) > 1:
                        authors.append(author_name)
                except Exception as e:
                    self.logger.debug(f"Skipping malformed author entry: {e}")
                    continue
        except Exception as e:
            self.logger.warning(f"Author extraction failed: {e}")
        
        if not authors:
            self.logger.warning("No authors found, using placeholder")
            authors = ["Unknown Author"]
        
        return authors
    
    def _extract_section_safe(self, div, index: int, title: str, authors: List[str]) -> Optional[Document]:
        """„Çª„ÇØ„Ç∑„Éß„É≥ÊäΩÂá∫Ôºà„Ç®„É©„ÉºËÄêÊÄßÔºâ"""
        try:
            # „Çª„ÇØ„Ç∑„Éß„É≥„Çø„Ç§„Éà„É´
            head = div.find('head')
            section_title = head.text.strip() if head and head.text else f"Section {index}"
            
            # „Éë„É©„Ç∞„É©„ÉïÊäΩÂá∫
            paragraphs = []
            for p in div.find_all('p'):
                text = p.get_text(strip=True)
                if text:
                    paragraphs.append(text)
            
            text = '\n\n'.join(paragraphs)
            
            # Á©∫„Çª„ÇØ„Ç∑„Éß„É≥„Çí„Çπ„Ç≠„ÉÉ„Éó
            if not text or len(text) < 50:
                self.logger.debug(f"Skipping empty/short section: {section_title}")
                return None
            
            return Document(
                text=text,
                metadata={
                    'title': title[:200],
                    'authors': ', '.join(authors[:5]),
                    'section': section_title[:100],
                    'section_index': index,
                    'char_count': len(text),
                    'paragraph_count': len(paragraphs)
                }
            )
        except Exception as e:
            self.logger.warning(f"Failed to extract section {index}: {e}")
            return None
    
    def evolve_to_notes(self, output_dir: str, granularity: str = 'section'):
        """
        üìù „Éé„Éº„Éà„Å´ÈÄ≤Âåñ: Ê∂≤Êô∂„ÅÆ„Çà„ÅÜ„Å´ÊÉÖÂ†±„ÇíÂèØË¶ñÂåñ
        
        Args:
            output_dir: Obsidian vault „ÅÆ„Éë„Çπ
            granularity: 'section' | 'paragraph' (v2.0) | 'sentence' (v3.0)
        """
        if not self.crystal:
            raise ValueError("‚ùå No crystal found. Run crystallize() first.")
        
        # Á≤íÂ∫¶„ÅÆË≠¶ÂëäÔºàÂ∞ÜÊù•„ÅÆÊã°ÂºµÁî®Ôºâ
        if granularity != 'section':
            self.logger.warning(f"Granularity '{granularity}' not yet implemented, using 'section'")
            # TODO: v2.0„ÅßÂÆüË£Ö
        
        self.logger.info("Evolving to observable notes...")
        self.logger.info("  ‚îú‚îÄ Generating markdown lattice")
        
        output_dir = Path(output_dir).expanduser()
        paper_title = self._sanitize(self.metadata['title'])
        paper_dir = output_dir / "Papers" / paper_title
        paper_dir.mkdir(parents=True, exist_ok=True)
        
        # ÂêÑ„Çª„ÇØ„Ç∑„Éß„É≥„ÇíMarkdownÂåñ
        for i, doc in enumerate(self.crystal):
            section = doc.metadata.get('section', 'Untitled')
            
            md_content = f"""---
title: {self.metadata['title']}
authors: {', '.join(self.metadata['authors'][:3])}
section: {section}
index: {i}
total: {len(self.crystal)}
type: paper-section
created: {time.strftime('%Y-%m-%d %H:%M:%S')}
---

# {section}

{doc.text}

---
**Navigation**
- [[{paper_title}_index|üìë Back to Index]]
{"- [[" + paper_title + f"_{i-1:03d}|‚Üê Previous]]" if i > 0 else ""}
{"- [[" + paper_title + f"_{i+1:03d}|Next ‚Üí]]" if i < len(self.crystal)-1 else ""}

**Metadata**
- Paragraphs: {doc.metadata.get('paragraph_count', 'N/A')}
- Characters: {doc.metadata.get('char_count', 'N/A')}
"""
            
            filename = f"{paper_title}_{i:03d}_{self._sanitize(section)}.md"
            filepath = paper_dir / filename
            
            with open(filepath, "w", encoding='utf-8') as f:
                f.write(md_content)
            
            self.logger.debug(f"  ‚îú‚îÄ {filename} ‚úì")
        
        # „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„Éö„Éº„Ç∏
        index_content = f"""---
title: {self.metadata['title']}
type: paper-index
authors: {', '.join(self.metadata['authors'])}
created: {time.strftime('%Y-%m-%d %H:%M:%S')}
---

# {self.metadata['title']}

**Authors:** {', '.join(self.metadata['authors'])}

## Sections

"""
        for i, doc in enumerate(self.crystal):
            section = doc.metadata.get('section', 'Untitled')
            index_content += f"{i+1}. [[{paper_title}_{i:03d}_{self._sanitize(section)}|{section}]]\n"
        
        index_path = paper_dir / f"{paper_title}_index.md"
        with open(index_path, "w", encoding='utf-8') as f:
            f.write(index_content)
        
        self.logger.info("  ‚îî‚îÄ Index matrix created")
        self.logger.info("‚úÖ Notes evolution complete")
        self.logger.info(f"   Location: {paper_dir}")
    
    def evolve_to_graph(self, graph_store: Neo4jGraphStore, normalize_labels: bool = False):
        """
        üï∏Ô∏è „Ç∞„É©„Éï„Å´ÈÄ≤Âåñ: Ê∞¥Êô∂Ê†ºÂ≠ê„ÅÆ„Çà„ÅÜ„Å´Ê¶ÇÂøµ„ÇíÈÖçÁΩÆ
        
        Args:
            graph_store: Neo4jGraphStore „Ç§„É≥„Çπ„Çø„É≥„Çπ
            normalize_labels: ‚ö†Ô∏è ÂÆüÈ®ìÁöÑÊ©üËÉΩÔºàv2.0„ÅßÂÆüË£Ö‰∫àÂÆöÔºâ
        """
        if not self.crystal:
            raise ValueError("‚ùå No crystal found. Run crystallize() first.")
        
        if normalize_labels:
            self.logger.warning("‚ö†Ô∏è Label normalization is not yet implemented (coming in v2.0)")
            # TODO: v2.0„ÅßÂÆüË£Ö
        
        self.logger.info("Evolving to crystal lattice structure...")
        
        # Neo4j„Çπ„Ç≠„Éº„ÉûÂàùÊúüÂåñ
        self._setup_neo4j_schema(graph_store)
        
        self.logger.info("  ‚îú‚îÄ Resonating with GPT-4o-mini")
        
        llm = OpenAI(model="gpt-4o-mini", timeout=120.0, max_retries=3)
        node_parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=50)
        storage_context = StorageContext.from_defaults(graph_store=graph_store)
        
        self.logger.info("  ‚îú‚îÄ Extracting concept nodes")
        self.logger.info("  ‚îú‚îÄ Forming relationship bonds")
        
        try:
            index = KnowledgeGraphIndex.from_documents(
                self.crystal,
                storage_context=storage_context,
                llm=llm,
                transformations=[node_parser],
                embed_model=HuggingFaceEmbedding(model_name="BAAI/bge-m3"),
                show_progress=False,
                max_triplets_per_chunk=10,
                include_embeddings=True,
            )
            
            # Data ProvenanceÔºàÂá∫ÂÖ∏ÊÉÖÂ†±Ôºâ„ÇíËøΩÂä†
            self._add_provenance(graph_store)
            
            kg = index.get_networkx_graph()
            
            self.logger.info("  ‚îú‚îÄ Injecting into Neo4j lattice")
            self.logger.info("  ‚îî‚îÄ Structure crystallized")
            self.logger.info("‚úÖ Graph evolution complete")
            self.logger.info(f"   Nodes: {len(kg.nodes)} | Edges: {len(kg.edges)}")
            
        except Exception as e:
            self.logger.error(f"Graph evolution failed: {e}", exc_info=True)
            raise
    
    def _setup_neo4j_schema(self, graph_store: Neo4jGraphStore):
        """Neo4j„Çπ„Ç≠„Éº„ÉûÂàùÊúüÂåñÔºàÂà∂Á¥Ñ„Éª„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÔºâ"""
        self.logger.debug("Setting up Neo4j schema...")
        
        try:
            with graph_store.client.session() as session:
                # UNIQUEÂà∂Á¥Ñ
                session.run("""
                    CREATE CONSTRAINT entity_id IF NOT EXISTS
                    FOR (n:Entity) REQUIRE n.id IS UNIQUE
                """)
                
                # „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÔºàÊ§úÁ¥¢È´òÈÄüÂåñÔºâ
                session.run("""
                    CREATE INDEX entity_name IF NOT EXISTS
                    FOR (n:Entity) ON (n.name)
                """)
                
                self.logger.debug("Neo4j schema initialized")
        except Exception as e:
            self.logger.warning(f"Schema setup failed (may already exist): {e}")
    
    def _add_provenance(self, graph_store: Neo4jGraphStore):
        """Data ProvenanceÔºàÂá∫ÂÖ∏ÊÉÖÂ†±Ôºâ„ÇíËøΩÂä†"""
        self.logger.debug("Adding provenance metadata...")
        
        try:
            with graph_store.client.session() as session:
                session.run("""
                    MATCH (n:Entity)
                    WHERE NOT EXISTS(n.source_paper)
                    SET n.source_paper = $title,
                        n.source_authors = $authors,
                        n.extracted_at = datetime(),
                        n.extractor_model = 'gpt-4o-mini',
                        n.extractor_version = '1.0'
                """, 
                title=self.metadata['title'], 
                authors=', '.join(self.metadata['authors']))
                
                self.logger.debug("Provenance metadata added")
        except Exception as e:
            self.logger.warning(f"Provenance addition failed: {e}")
    
    def evolve_all(self, markdown_dir: str, graph_store: Neo4jGraphStore):
        """
        üåü ÂÆåÂÖ®ÈÄ≤Âåñ: ÂÖ®ÂΩ¢ÊÖã„Å´ÂÖ±ÊåØ
        
        Args:
            markdown_dir: MarkdownÂá∫ÂäõÂÖà
            graph_store: Neo4jGraphStore
        """
        if not self.crystal:
            raise ValueError("‚ùå No crystal found. Run crystallize() first.")
        
        self.logger.info("Resonating across all forms...")
        
        start_time = time.time()
        
        try:
            # ‰∏¶Ë°åÂá¶ÁêÜ
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                notes_future = executor.submit(self.evolve_to_notes, markdown_dir)
                graph_future = executor.submit(self.evolve_to_graph, graph_store)
                
                notes_future.result()
                graph_future.result()
            
            elapsed = time.time() - start_time
            self.logger.info(f"All forms resonating in harmony (took {elapsed:.1f}s)")
            
        except Exception as e:
            self.logger.error(f"Evolution failed: {e}", exc_info=True)
            raise
    
    def export_graph(self, format: str = 'neo4j', output_path: Optional[str] = None):
        """
        „Ç∞„É©„Éï„Çí„Ç®„ÇØ„Çπ„Éù„Éº„ÉàÔºàÊã°ÂºµÁî®„Çπ„É≠„ÉÉ„ÉàÔºâ
        
        Args:
            format: 'neo4j' | 'json-ld' (v2.0) | 'rdf' (v2.0) | 'custom' (v3.0)
            output_path: Âá∫ÂäõÂÖàÔºàformat„Å´„Çà„ÇãÔºâ
        """
        exporters = {
            'neo4j': self._export_neo4j,
            'json-ld': self._export_jsonld,
            'rdf': self._export_rdf,
            'custom': self._export_custom
        }
        
        if format not in exporters:
            raise ValueError(f"Unknown format: {format}. Supported: {list(exporters.keys())}")
        
        self.logger.info(f"Exporting to {format}...")
        return exporters[format](output_path)
    
    def _export_neo4j(self, output_path: Optional[str] = None):
        """Neo4jÔºà„Éá„Éï„Ç©„É´„ÉàÔºâ"""
        self.logger.info("Neo4j is the default storage, no export needed")
        return None
    
    def _export_jsonld(self, output_path: str):
        """JSON-LDÔºàÊ±éÁî®Ôºâ- v2.0ÂÆüË£Ö‰∫àÂÆö"""
        raise NotImplementedError("JSON-LD export coming in v2.0")
    
    def _export_rdf(self, output_path: str):
        """RDF/TurtleÔºàBlazegraphÁî®Ôºâ- v2.0ÂÆüË£Ö‰∫àÂÆö"""
        raise NotImplementedError("RDF export coming in v2.0")
    
    def _export_custom(self, output_path: str):
        """„Ç´„Çπ„Çø„É†„Éó„É©„Ç∞„Ç§„É≥ - v3.0ÂÆüË£Ö‰∫àÂÆö"""
        raise NotImplementedError("Custom plugins coming in v3.0")
    
    def _sanitize(self, text: str) -> str:
        """„Éï„Ç°„Ç§„É´ÂêçÁî®„ÅÆ„Çµ„Éã„Çø„Ç§„Ç∫"""
        sanitized = re.sub(r'[<>:"/\\|?*]', '', text)
        return sanitized[:50].strip()


# CLI
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Crystal Evoluder - Knowledge Crystallization System',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Crystallize only
  python crystal_evoluder.py crystallize paper.tei.xml
  
  # Generate notes
  python crystal_evoluder.py evolve-notes paper.tei.xml --markdown-dir ~/Notes
  
  # Build knowledge graph
  python crystal_evoluder.py evolve-graph paper.tei.xml --neo4j-pass mypass
  
  # Do everything
  python crystal_evoluder.py evolve-all paper.tei.xml --neo4j-pass mypass
        """
    )
    
    parser.add_argument('command', choices=['crystallize', 'evolve-notes', 'evolve-graph', 'evolve-all'])
    parser.add_argument('tei_file', help='TEI XML file path')
    parser.add_argument('--markdown-dir', default='~/CrystalEvoluder/Library', help='Markdown output directory')
    parser.add_argument('--neo4j-uri', default='bolt://localhost:7687', help='Neo4j connection URI')
    parser.add_argument('--neo4j-user', default='neo4j', help='Neo4j username')
    parser.add_argument('--neo4j-pass', help='Neo4j password (required for graph operations)')
    parser.add_argument('--api-key', help='OpenAI API key (or set OPENAI_API_KEY env var)')
    parser.add_argument('--strict', action='store_true', help='Strict mode: fail on any error')
    parser.add_argument('--debug', action='store_true', help='Enable debug logging')
    
    args = parser.parse_args()
    
    # „É≠„ÇÆ„É≥„Ç∞„É¨„Éô„É´
    log_level = logging.DEBUG if args.debug else logging.INFO
    
    # API„Ç≠„ÉºË®≠ÂÆö
    if args.api_key:
        os.environ['OPENAI_API_KEY'] = args.api_key
    
    # „Éò„ÉÉ„ÉÄ„Éº
    print("üîÆ Crystal Evoluder v1.0.0")
    print("‚îÅ" * 42)
    
    start_time = time.time()
    
    try:
        evoluder = CrystalEvoluder(log_level=log_level)
        evoluder.crystallize(args.tei_file, strict_mode=args.strict)
        
        if args.command in ['evolve-notes', 'evolve-all']:
            evoluder.evolve_to_notes(args.markdown_dir)
        
        if args.command in ['evolve-graph', 'evolve-all']:
            if not args.neo4j_pass:
                raise ValueError("--neo4j-pass required for graph operations")
            
            graph_store = Neo4jGraphStore(
                username=args.neo4j_user,
                password=args.neo4j_pass,
                url=args.neo4j_uri,
            )
            evoluder.evolve_to_graph(graph_store)
        
        elapsed = time.time() - start_time
        print("\n" + "‚îÅ" * 42)
        print(f"‚ú® Process completed in {int(elapsed//60)}m {int(elapsed%60)}s")
        print("üíé Knowledge crystallization successful")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        exit(1)