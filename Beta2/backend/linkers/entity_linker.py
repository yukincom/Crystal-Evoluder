"""
ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£çµ±åˆã‚¯ãƒ©ã‚¹
"""
import numpy as np
from typing import List, Dict, Any, Tuple
from collections import defaultdict

import networkx as nx
from model import ensure_bge_m3


class EntityLinker:
    """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®çµ±åˆãƒ»ãƒªãƒ³ã‚¯ã‚’æ‹…å½“"""

    def __init__(self, config: dict, logger):
        self.config = config
        self.logger = logger

    def link_entities(
        self,
        kg: nx.Graph,
        similarity_threshold: float = 0.88,
        use_embedding: bool = True
    ) -> Tuple[nx.Graph, Dict[str, str]]:
        """
        åŒä¸€å®Ÿä½“ã‚’çµ±åˆã—ã¦ã‚°ãƒ©ãƒ•ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

        Args:
            kg: NetworkXã‚°ãƒ©ãƒ•
            similarity_threshold: çµ±åˆã™ã‚‹é¡ä¼¼åº¦ã®é–¾å€¤ï¼ˆ0.95æ¨å¥¨ï¼‰
            use_embedding: True=åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ã€False=æ–‡å­—åˆ—é¡ä¼¼åº¦

        Returns:
            (çµ±åˆå¾Œã®ã‚°ãƒ©ãƒ•, ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒãƒƒãƒ”ãƒ³ã‚°)

        ä¾‹:
            mapping = {
                'Self-Attention': 'self_attention',
                'the attention mechanism': 'self_attention',
                'it': 'self_attention'  # corefè§£æ±ºãŒå¿…è¦
            }
        """
        self.logger.info(f"ğŸ”— Starting entity linking (threshold={similarity_threshold})")

        nodes = list(kg.nodes())
        entity_mapping = {}  # old_name -> canonical_name
        clusters = []  # [[é¡ä¼¼ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ãƒªã‚¹ãƒˆ], ...]

        # ============================================================
        # 1. ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        # ============================================================
        if use_embedding:
            clusters = self._cluster_entities_by_embedding(
                nodes, similarity_threshold
            )
        else:
            clusters = self._cluster_entities_by_string(nodes)

        # ============================================================
        # 2. å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ä»£è¡¨åã‚’æ±ºå®š
        # ============================================================
        for cluster in clusters:
            if len(cluster) <= 1:
                continue

            # ä»£è¡¨åã®é¸æŠæˆ¦ç•¥
            canonical = self._select_canonical_name(cluster, kg)

            for entity in cluster:
                if entity != canonical:
                    entity_mapping[entity] = canonical

        self.logger.info(f"  â†’ {len(entity_mapping)} entities will be merged")

        # ============================================================
        # 3. ã‚°ãƒ©ãƒ•ã®çµ±åˆ
        # ============================================================
        merged_kg = self._merge_graph_entities(kg, entity_mapping)

        self.logger.info(
            f"âœ… Entity linking complete: "
            f"{len(kg.nodes)} â†’ {len(merged_kg.nodes)} nodes"
        )

        return merged_kg, entity_mapping

    def _cluster_entities_by_embedding(
        self,
        entities: List[str],
        threshold: float
    ) -> List[List[str]]:
        """
        åŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°

        Returns:
            [[é¡ä¼¼ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£], [é¡ä¼¼ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£], ...]
        """
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®åŸ‹ã‚è¾¼ã¿è¨ˆç®—
        embeddings = []
        valid_entities = []

        for entity in entities:
            try:
                embed_model = ensure_bge_m3()
                emb = embed_model.get_text_embedding(entity)
                emb = np.array(emb, dtype=np.float32)
                norm = np.linalg.norm(emb)

                if norm > 1e-9:
                    emb = emb / norm
                    embeddings.append(emb)
                    valid_entities.append(entity)
            except Exception as e:
                self.logger.debug(f"Embedding failed for '{entity}': {e}")

        if len(embeddings) == 0:
            return []

        embeddings = np.vstack(embeddings)

        # é¡ä¼¼åº¦ãƒãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        sim_matrix = embeddings @ embeddings.T

        # Union-Find ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        parent = {i: i for i in range(len(valid_entities))}

        def find(x):
            if parent[x] != x:
                parent[x] = find(parent[x])
            return parent[x]

        def union(x, y):
            px, py = find(x), find(y)
            if px != py:
                parent[px] = py

        # é¡ä¼¼åº¦ãŒé–¾å€¤ä»¥ä¸Šã®ãƒšã‚¢ã‚’çµ±åˆ
        for i in range(len(valid_entities)):
            for j in range(i + 1, len(valid_entities)):
                if sim_matrix[i, j] >= threshold:
                    union(i, j)

        # ã‚¯ãƒ©ã‚¹ã‚¿ã‚’æ§‹ç¯‰
        clusters_dict = {}
        for i, entity in enumerate(valid_entities):
            root = find(i)
            if root not in clusters_dict:
                clusters_dict[root] = []
            clusters_dict[root].append(entity)

        clusters = list(clusters_dict.values())

        self.logger.info(
            f"  â†’ Found {len(clusters)} clusters from {len(valid_entities)} entities"
        )

        return clusters

    def _cluster_entities_by_string(
        self,
        entities: List[str]
    ) -> List[List[str]]:
        """
        æ–‡å­—åˆ—é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆé«˜é€Ÿã ãŒç²¾åº¦ä½ã„ï¼‰

        ä½¿ç”¨ã‚±ãƒ¼ã‚¹ï¼š
        - "Self-Attention" ã¨ "self-attention" ã‚’çµ±åˆ
        - "GPT-3" ã¨ "GPT3" ã‚’çµ±åˆ
        """

        clusters_dict = {}
        normalized = {}

        for entity in entities:
            # æ­£è¦åŒ–ï¼ˆå°æ–‡å­—åŒ–ã€è¨˜å·é™¤å»ï¼‰
            norm = entity.lower().replace('-', '').replace('_', '').replace(' ', '')
            normalized[entity] = norm
            if norm not in clusters_dict:
                clusters_dict[norm] = []
            clusters_dict[norm].append(entity)

        # 2ã¤ä»¥ä¸Šã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒã‚ã‚‹æ­£è¦åŒ–å½¢ã®ã¿è¿”ã™
        clusters = [v for v in clusters_dict.values() if len(v) > 1]

        return clusters

    def _select_canonical_name(
        self,
        cluster: List[str],
        kg: nx.Graph
    ) -> str:
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ã®ä»£è¡¨åã‚’é¸æŠ

        æˆ¦ç•¥ï¼š
        1. æœ€ã‚‚æ¬¡æ•°ãŒé«˜ã„ï¼ˆå¤šãã®é–¢ä¿‚ã‚’æŒã¤ï¼‰
        2. æœ€ã‚‚é•·ã„åå‰ï¼ˆæƒ…å ±é‡ãŒå¤šã„ï¼‰
        3. ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †
        """
        # æ¬¡æ•°ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        scores = {}
        for entity in cluster:
            degree = kg.degree(entity) if kg.has_node(entity) else 0
            length = len(entity)

            # ã‚¹ã‚³ã‚¢ = æ¬¡æ•° * 10 + é•·ã•
            scores[entity] = degree * 10 + length

        # ã‚¹ã‚³ã‚¢ãŒæœ€å¤§ã®ã‚‚ã®ã‚’é¸æŠ
        canonical = max(cluster, key=lambda e: scores[e])

        self.logger.debug(
            f"  Cluster: {cluster} â†’ Canonical: '{canonical}'"
        )

        return canonical

    def _merge_graph_entities(
        self,
        kg: nx.Graph,
        entity_mapping: Dict[str, str]
    ) -> nx.Graph:
        """
        ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒãƒƒãƒ”ãƒ³ã‚°ã«å¾“ã£ã¦ã‚°ãƒ©ãƒ•ã‚’çµ±åˆ

        Args:
            kg: å…ƒã®ã‚°ãƒ©ãƒ•
            entity_mapping: {old_name: canonical_name}

        Returns:
            çµ±åˆå¾Œã®ã‚°ãƒ©ãƒ•
        """
        merged_kg = nx.Graph()

        # ãƒãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆãƒãƒƒãƒ”ãƒ³ã‚°é©ç”¨ï¼‰
        for node, data in kg.nodes(data=True):
            canonical = entity_mapping.get(node, node)

            if merged_kg.has_node(canonical):
                # æ—¢å­˜ãƒãƒ¼ãƒ‰ã®å±æ€§ã‚’ãƒãƒ¼ã‚¸
                for key, value in data.items():
                    if key not in merged_kg.nodes[canonical]:
                        merged_kg.nodes[canonical][key] = value
            else:
                merged_kg.add_node(canonical, **data)

        # ã‚¨ãƒƒã‚¸ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆãƒãƒƒãƒ”ãƒ³ã‚°é©ç”¨ + é‡ã¿çµ±åˆï¼‰
        edge_weights = {}
        
        edge_weights = defaultdict(lambda: {
            'weight': 0.0,
            'intra_raw': 0.0,
            'inter_raw': 0.0,
            'relations': []
        })

        for u, v, data in kg.edges(data=True):
            u_canonical = entity_mapping.get(u, u)
            v_canonical = entity_mapping.get(v, v)

            # è‡ªå·±ãƒ«ãƒ¼ãƒ—ã¯é™¤å¤–
            if u_canonical == v_canonical:
                continue

            # æ­£è¦åŒ–ã•ã‚ŒãŸã‚¨ãƒƒã‚¸ã‚­ãƒ¼ï¼ˆæ–¹å‘ãªã—ï¼‰
            edge_key = tuple(sorted([u_canonical, v_canonical]))

            # é‡ã¿ã‚’ç´¯ç©
            edge_weights[edge_key]['weight'] += data.get('weight', 0.0)
            edge_weights[edge_key]['intra_raw'] += data.get('intra_raw', 0.0)
            edge_weights[edge_key]['inter_raw'] += data.get('inter_raw', 0.0)

            # é–¢ä¿‚ã‚¿ã‚¤ãƒ—ã‚’è¨˜éŒ²
            rel = data.get('relation', 'RELATED')
            if rel not in edge_weights[edge_key]['relations']:
                edge_weights[edge_key]['relations'].append(rel)

        # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
        for (u, v), weights in edge_weights.items():
            merged_kg.add_edge(
                u, v,
                weight=weights['weight'],
                intra_raw=weights['intra_raw'],
                inter_raw=weights['inter_raw'],
                relation=weights['relations'][0] if weights['relations'] else 'RELATED',
                relation_types=weights['relations']
            )

        return merged_kg