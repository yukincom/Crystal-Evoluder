"""
ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼ï¼ˆQwen 8Bï¼‰
"""
import logging
import json
import re
import csv
import requests

from pathlib import Path
from typing import List, Dict, Any
from llama_index.core import Document
import numpy as np

class DataQualityChecker:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLM: Qwen 8Bï¼‰"""
    
    def __init__(self, ollama_url: str = 'http://localhost:11434', logger: logging.Logger = None):
        self.ollama_url = ollama_url
        self.logger = logger or logging.getLogger('DataQualityChecker')
        self.ollama_available = self._check_ollama()
        
        self.embedding_cache = None

        if self.ollama_available:
            self.logger.info("âœ… Ollama (Qwen 8B) available")
        else:
            self.logger.warning("âš ï¸  Ollama not available (quality check disabled)")

    def set_embedding_cache(self, embedding_cache):
        """å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¨­å®š"""
        self.embedding_cache = embedding_cache
        if self.embedding_cache:
            self.logger.info("âœ… BGE-M3 embedding cache set for quality check")
        else:
            self.logger.warning("âš ï¸ No embedding cache provided for quality check")

    def _check_ollama(self) -> bool:
        """OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False

    def check_documents(self, documents: List[Document], output_dir: str = './review') -> Dict[str, Any]:
        """
        Documentã®å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆBGE-M3ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç‰ˆï¼‰
        """
        clean = []
        flagged = []

        for i, doc in enumerate(documents):
            self.logger.info(f"Checking {i+1}/{len(documents)}: {doc.metadata.get('section', 'Unknown')}")

            issues = self._detect_issues(doc)

            if not issues:
                clean.append(doc)
            else:
                severity = self._determine_severity(issues)
                flagged.append({
                    'document': doc,
                    'issues': [issue['type'] for issue in issues],
                    'reasons': [issue['reason'] for issue in issues],
                    'severity': severity
                })

        stats = {
            'total': len(documents),
            'clean': len(clean),
            'flagged': len(flagged)
        }

        if flagged:
            self._save_review_queue(flagged, output_dir)

        return {'clean': clean, 'flagged': flagged, 'stats': stats}

    def _detect_issues(self, doc: Document) -> List[Dict]:
        """BGE-M3ã§ç²—ãƒã‚§ãƒƒã‚¯ + ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§Qwenæœ€çµ‚ç¢ºèª"""
        issues = []

        text = doc.text.strip()
        if not text:
            issues.append({'type': 'empty', 'reason': 'Document is empty'})
            return issues

        # BGE-M3ç²—ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ»é«˜é€Ÿï¼‰
        if self.embedding_cache:
            try:
                text_emb = self.embedding_cache.get_embedding(text)
                specificity = np.linalg.norm(text_emb) / 0.5  # å…·ä½“æ€§ã‚¹ã‚³ã‚¢
                if specificity < 0.6:
                    issues.append({'type': 'too_abstract', 'reason': 'Text lacks specificity (low embedding norm)'})

                # çŸ­ã™ããƒã‚§ãƒƒã‚¯ï¼ˆåŸ‹ã‚è¾¼ã¿å¯†åº¦ï¼‰
                sentences = [s.strip() for s in text.split('\n') if s.strip()]
                if len(sentences) < 3:
                    issues.append({'type': 'too_short', 'reason': 'Too few sentences'})

                # çŸ›ç›¾ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ï¼šæ–‡é–“é¡ä¼¼åº¦ãŒç•°å¸¸ã«é«˜ã„/ä½ã„ï¼‰
                if len(sentences) > 1:
                    embs = [self.embedding_cache.get_embedding(s) for s in sentences[:5]]  # å…ˆé ­5æ–‡ã ã‘
                    sims = [np.dot(embs[i], embs[i+1]) / (np.linalg.norm(embs[i]) * np.linalg.norm(embs[i+1]) + 1e-9)
                            for i in range(len(embs)-1)]
                    if any(sim > 0.98 for sim in sims):  # ã»ã¼åŒä¸€æ–‡é€£ç¶š â†’ çŸ›ç›¾/é‡è¤‡
                        issues.append({'type': 'potential_contradiction', 'reason': 'High similarity between consecutive sentences'})
            except Exception as e:
                self.logger.warning(f"BGE-M3 coarse check failed: {e}")

        # Qwen 8Bæœ€çµ‚ç¢ºèªï¼ˆå•é¡Œãƒ•ãƒ©ã‚°ç«‹ã£ãŸã‚‚ã®ã ã‘ï¼‰
        if issues and self.ollama_available:
            ollama_issues = self._ollama_check(text)
            issues.extend(ollama_issues)

        return issues

    def _ollama_check(self, documents: List[Document], output_dir: str = './review') -> Dict[str, Any]: 
        """
        Document ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯

        Returns:
            {
                'clean': [Document, ...],      # å•é¡Œãªã—
                'flagged': [                    # è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    {
                        'document': Document,
                        'issues': ['missing_subject', ...],
                        'reasons': ['ä¸»èªãŒæ¬ è½', ...],
                        'severity': 'high' | 'medium' | 'low'
                    },
                    ...
                ],
                'stats': {...}
            }
        """
        if not self.ollama_available:
            self.logger.warning("Ollama not available, skipping quality check")
            return {'clean': documents, 'flagged': [], 'stats': {'total': len(documents), 'clean': len(documents), 'flagged': 0}}

        self.logger.info(f"ğŸ” Checking quality of {len(documents)} documents...")

        clean = []
        flagged = []

        for i, doc in enumerate(documents):
            self.logger.info(f"  Checking {i+1}/{len(documents)}: {doc.metadata.get('section', 'Unknown')}")

            issues = self._detect_issues(doc)

            if issues:
                flagged.append({
                    'document': doc,
                    'issues': [issue['type'] for issue in issues],
                    'reasons': [issue['reason'] for issue in issues],
                    'severity': self._assess_severity(issues),
                    'metadata': doc.metadata
                })
            else:
                clean.append(doc)

        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚­ãƒ¥ãƒ¼ä¿å­˜
        if flagged:
            self._save_review_queue(flagged, output_dir)

        stats = {
            'total': len(documents),
            'clean': len(clean),
            'flagged': len(flagged),
            'high_severity': sum(1 for f in flagged if f['severity'] == 'high'),
            'medium_severity': sum(1 for f in flagged if f['severity'] == 'medium'),
            'low_severity': sum(1 for f in flagged if f['severity'] == 'low')
        }

        self.logger.info(
            f"âœ… Quality check complete: "
            f"{stats['clean']} clean, {stats['flagged']} flagged "
            f"(high: {stats['high_severity']}, medium: {stats['medium_severity']}, low: {stats['low_severity']})"
        )

        return {
            'clean': clean,
            'flagged': flagged,
            'stats': stats
        }

    def _has_figure_context(self, text: str) -> bool:
        """å›³è¡¨å‚ç…§ã«ååˆ†ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹ã‹"""
        # ç°¡æ˜“ãƒã‚§ãƒƒã‚¯: å›³è¡¨å‚ç…§ã®å‰å¾Œã«èª¬æ˜ãŒã‚ã‚‹
        patterns = [
            r'å›³\s*\d+.*?[ã€‚\.]',
            r'Figure\s*\d+.*?\.',
            r'è¡¨\s*\d+.*?[ã€‚\.]',
            r'Table\s*\d+.*?\.'
        ]
        for pattern in patterns:
            if re.search(pattern, text):
                return True
        return False

    def _needs_ai_check(self, text: str) -> bool:
        """AIã«ã‚ˆã‚‹è©³ç´°ãƒã‚§ãƒƒã‚¯ãŒå¿…è¦ã‹åˆ¤å®š"""
        # æ§‹é€ ãŒè¤‡é›‘ãªå ´åˆã®ã¿AIãƒã‚§ãƒƒã‚¯
        suspicious_patterns = [
            'ä¸æ˜', 'ä¸Šè¨˜', 'å‰è¿°', 'ä»¥ä¸‹',
            '...', 'â€»', 'ï¼Š',
            len(text.split('ã€‚')) > 10,  # é•·æ–‡
            text.count('ã€') > 20         # è¤‡é›‘ãªæ§‹é€ 
        ]
        return any(suspicious_patterns)

    def _ai_deep_check(self, text: str) -> List[Dict[str, str]]:
        """Qwen 8B ã§è©³ç´°ãƒã‚§ãƒƒã‚¯"""
        prompt = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

            ãƒ†ã‚­ã‚¹ãƒˆ:
            {text[:500]}...

            ä»¥ä¸‹ã®è¦³ç‚¹ã§ãƒã‚§ãƒƒã‚¯:
            1. ä¸»èªã®æ¬ è½ï¼ˆæ–‡è„ˆãŒä¸æ˜ç¢ºï¼‰
            2. çŸ›ç›¾ã™ã‚‹è¨˜è¿°
            3. å›³è¡¨å‚ç…§ã®æ¬ è½
            4. æ–‡ç« ã®ç ´æï¼ˆé€”ä¸­ã§åˆ‡ã‚Œã¦ã„ã‚‹ç­‰ï¼‰

            å•é¡ŒãŒã‚ã‚Œã°JSONå½¢å¼ã§å‡ºåŠ›:
            {{"issues": [{{"type": "å•é¡Œã‚¿ã‚¤ãƒ—", "reason": "ç†ç”±"}}]}}

            å•é¡ŒãŒãªã‘ã‚Œã°:
            {{"issues": []}}
            """

        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    'model': 'qwen2.5:32b',
                    'prompt': prompt,
                    'stream': False
                },
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                response_text = result.get('response', '{}')

                # JSONæŠ½å‡ºï¼ˆAIã®å‡ºåŠ›ã‹ã‚‰ï¼‰
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                    return data.get('issues', [])

        except Exception as e:
            self.logger.warning(f"AI check failed: {e}")

        return []

    def _assess_severity(self, issues: List[Dict[str, str]]) -> str:
        """å•é¡Œã®æ·±åˆ»åº¦ã‚’åˆ¤å®š"""
        severity_map = {
            'missing_subject': 'high',
            'contradiction': 'high',
            'missing_visual': 'medium',
            'too_short': 'low',
            'structural_damage': 'high'
        }

        max_severity = 'low'
        for issue in issues:
            issue_severity = severity_map.get(issue['type'], 'low')
            if issue_severity == 'high':
                return 'high'
            if issue_severity == 'medium' and max_severity == 'low':
                max_severity = 'medium'

        return max_severity

    def _save_review_queue(self, flagged: List[Dict], output_dir: str):
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚­ãƒ¥ãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # CSVå½¢å¼
        import csv
        csv_path = output_path / 'review_queue.csv'
        with open(csv_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Section', 'Severity', 'Issues', 'Reasons', 'Text Preview'])

            for item in flagged:
                writer.writerow([
                    item['metadata'].get('section', 'Unknown'),
                    item['severity'],
                    ', '.join(item['issues']),
                    ', '.join(item['reasons']),
                    item['document'].text[:100] + '...'
                ])

        # JSONå½¢å¼ï¼ˆè©³ç´°æƒ…å ±ï¼‰
        json_path = output_path / 'review_queue.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump([
                {
                    'section': item['metadata'].get('section'),
                    'severity': item['severity'],
                    'issues': item['issues'],
                    'reasons': item['reasons'],
                    'text': item['document'].text,
                    'metadata': item['metadata']
                }
                for item in flagged
            ], f, ensure_ascii=False, indent=2)

        self.logger.info(f"ğŸ“ Review queue saved:")
        self.logger.info(f"   CSV: {csv_path}")
        self.logger.info(f"   JSON: {json_path}")