import React, { useState, useEffect } from 'react';
import { getConfig, saveConfig, testAIConnection } from '../api/client';
import type { Config } from '../types';
import './AISettings.css';

interface OllamaModel {
  name: string;
  size: number;
  capable: boolean;
  is_vision: boolean;
}

export const AISettings: React.FC = () => {
  const [config, setConfig] = useState<Config | null>(null);
  const [loading, setLoading] = useState(false);
  const [testingAI, setTestingAI] = useState(false);
  const [testingRefiner, setTestingRefiner] = useState(false);
  const [customRefiner, setCustomRefiner] = useState(false);

  // Ollamaãƒ¢ãƒ‡ãƒ«ä¸€è¦§
  const [ollamaModels, setOllamaModels] = useState<OllamaModel[]>([]);
  const [ollamaAvailable, setOllamaAvailable] = useState(false);
  const [loadingModels, setLoadingModels] = useState(false);

  // LLMç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆVisionã‚’é™¤å¤–ï¼‰
  const llmModels = ollamaModels.filter(m => !m.is_vision);
  
  // Visionç”¨ãƒ¢ãƒ‡ãƒ«
  const visionModels = ollamaModels.filter(m => m.is_vision);

  useEffect(() => {
    loadOllamaModels();
    loadConfig();
  }, []);

  useEffect(() => {
    // configãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã‚‰ã€refiner_modeãŒnullã§ãªã‘ã‚Œã°ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã¨åˆ¤å®š
    if (config && config.ai.refiner_mode !== null) {
      setCustomRefiner(true);
    }
  }, [config]);

  useEffect(() => {
    // Ollamaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¾Œã€configãŒã‚ã‚Œã°æ¤œè¨¼
    if (!config || !ollamaModels.length) return;

    // Ollamaãƒ¢ãƒ¼ãƒ‰ã‹ã¤ã€ollama_modelãŒæœªè¨­å®š or ç„¡åŠ¹ãªå ´åˆ
    if (config.ai.mode === 'ollama') {
      const currentModel = config.ai.ollama_model;
      
      if (!currentModel || currentModel === '') {
        // æœ‰åŠ¹ãªæœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•è¨­å®š
        const firstValidModel = llmModels.find(m => m.capable);
        if (firstValidModel) {
          setConfig({
            ...config,
            ai: {
              ...config.ai,
              ollama_model: firstValidModel.name
            }
          });
          console.log('âœ… Auto-selected Ollama model:', firstValidModel.name);
        }
      } else {
        // è¨­å®šã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒæœ‰åŠ¹ã‹ç¢ºèª
        const validModel = llmModels.find(m => 
          m.name === currentModel && m.capable
        );
        
        if (!validModel) {
          console.warn('âš ï¸ ç„¡åŠ¹ãªOllamaãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™:', currentModel);
          // æœ‰åŠ¹ãªæœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆ
          const firstValidModel = llmModels.find(m => m.capable);
          if (firstValidModel) {
            setConfig({
              ...config,
              ai: {
                ...config.ai,
                ollama_model: firstValidModel.name
              }
            });
            console.log('âœ… Replaced with valid Ollama model:', firstValidModel.name);
          }
        }
      }
    }
  }, [config, ollamaModels, llmModels]);

  const loadConfig = async () => {
    try {
      const data = await getConfig();
    // ğŸ”§ è¿½åŠ : è¨­å®šã®æ¤œè¨¼ã¨ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    if (data.ai.mode === 'ollama' && data.ai.ollama_model) {
      // ollama_modelãŒå®Ÿåœ¨ã™ã‚‹ã‹ç¢ºèªï¼ˆllmModelsãŒã¾ã ç©ºã®å ´åˆã¯å¾Œã§useEffectãŒå‡¦ç†ï¼‰
      console.log('Loaded ollama_model:', data.ai.ollama_model);
    }
    
    // refiner_modelã‚‚æ¤œè¨¼
    if (data.ai.refiner_model && data.ai.refiner_mode === 'ollama') {
      console.log('Loaded refiner_model:', data.ai.refiner_model);
    }
      setConfig(data);
    } catch (error) {
      console.error('Failed to load config:', error);
    }
  };

  const loadOllamaModels = async () => {
    setLoadingModels(true);
    try {
      const response = await fetch('http://localhost:8000/config/ollama/models');
      const data = await response.json();
      
      if (data.available) {
        setOllamaAvailable(true);
        setOllamaModels(data.models);
      } else {
        setOllamaAvailable(false);
        setOllamaModels([]);
      }
    } catch (error) {
      console.error('Failed to load Ollama models:', error);
      setOllamaAvailable(false);
    } finally {
      setLoadingModels(false);
    }
  };

  const handleSave = async () => {
    if (!config) return;
    setLoading(true);
    try {
      await saveConfig(config);
      alert('âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ');
    } catch (error) {
      alert('âŒ ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ');
    } finally {
      setLoading(false);
    }
  };

  const handleTestAI = async () => {
    if (!config) return;
    setTestingAI(true);
    try {
      const testConfig = {
        mode: config.ai.mode,
        api_key: config.ai.api_key,
        ollama_url: config.ai.ollama_url,
        api_model: config.ai.api_model,      
        ollama_model: config.ai.ollama_model, 
      };

      const result = await testAIConnection(testConfig);
      alert(result.message || 'âœ… æ¥ç¶šæˆåŠŸï¼');
    } catch (error: any) {
      alert(`âŒ æ¥ç¶šå¤±æ•—: ${error.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
    } finally {
      setTestingAI(false);
    }
  };

  const handleTestRefiner = async () => {
    if (!config) return;
    setTestingRefiner(true);
    try {
      const currentModel = config.ai.mode === 'api' 
        ? config.ai.api_model 
        : config.ai.ollama_model;
      
      const refinerConfig = {
        mode: config.ai.refiner_mode || config.ai.mode,
        api_key: config.ai.refiner_api_key || config.ai.api_key,
        ollama_url: config.ai.refiner_ollama_url || config.ai.ollama_url,
        ollama_model: config.ai.refiner_model || currentModel,
        api_model: config.ai.refiner_model || currentModel,
      };
      
      const result = await testAIConnection(refinerConfig);
      alert(result.message || 'âœ… Refineræ¥ç¶šæˆåŠŸï¼');
    } catch (error: any) {
      alert(`âŒ Refineræ¥ç¶šå¤±æ•—: ${error.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
    } finally {
      setTestingRefiner(false);
    }
  };

  const handleInputChange = (section: keyof Config, field: string, value: any) => {
    if (!config) return;
    
    setConfig({
      ...config,
      [section]: {
        ...config[section],
        [field]: value
      }
    });
  };

  const getCurrentModel = (): string => {
    if (!config) return '(æœªè¨­å®š)';
    return config.ai.mode === 'api' 
      ? config.ai.api_model || '(æœªæŒ‡å®š)' 
      : config.ai.ollama_model || '(æœªæŒ‡å®š)';
  };

  const handleCustomRefinerToggle = (enabled: boolean) => {
    if (!config) return;
    
    setCustomRefiner(enabled);
    
    if (enabled) {
      // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’æœ‰åŠ¹åŒ–ï¼šç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
      let currentModel = config.ai.mode === 'api' 
        ? config.ai.api_model 
        : config.ai.ollama_model;
      
    // ğŸ”§ ä¿®æ­£: Ollamaãƒ¢ãƒ¼ãƒ‰ã§ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    if (config.ai.mode === 'ollama') {
      const isValidModel = llmModels.some(m => m.name === currentModel && m.capable);
      
      if (!isValidModel || !currentModel) {
        // æœ‰åŠ¹ãªæœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        const firstValidModel = llmModels.find(m => m.capable);
        currentModel = firstValidModel?.name || '';
        
        console.warn('ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«ãŒæ¤œå‡ºã•ã‚ŒãŸãŸã‚ã€è‡ªå‹•ä¿®æ­£ã—ã¾ã—ãŸ:', currentModel);
      }
    }
    
    // ğŸ”§ ä¿®æ­£: APIãƒ¢ãƒ¼ãƒ‰ã§ç©ºã®å ´åˆã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
    if (config.ai.mode === 'api' && !currentModel) {
      currentModel = 'gpt-4o-mini';
    }


      setConfig({
        ...config,
        ai: {
        ...config.ai,
        refiner_mode: null,
        refiner_model: null,
        refiner_api_key: null,
        refiner_ollama_url: null
        }
      });
    } else {
      // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’ç„¡åŠ¹åŒ–
      setConfig({
        ...config,
        ai: {
          ...config.ai,
          refiner_mode: null,
          refiner_model: null,
          refiner_api_key: null,
          refiner_ollama_url: null
        }
      });
    }
  };

  if (!config) return <div>Loading...</div>;

  return (
    <div className="ai-settings">
      <h2>AI è¨­å®š</h2>

      {/* Ollamaæ¥ç¶šçŠ¶æ…‹ */}
      {loadingModels && (
        <div className="info-box">â³ Ollamaãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...</div>
      )}
      
      {!loadingModels && !ollamaAvailable && (
        <div className="warning-box">
          âš ï¸ OllamaãŒæ¥ç¶šã§ãã¾ã›ã‚“ã€‚Local AIãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€Ollamaã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
          <button onClick={loadOllamaModels} className="btn-small">ğŸ”„ å†èª­è¾¼</button>
        </div>
      )}

      {/* åŸºæœ¬ãƒ¢ãƒ‡ãƒ«è¨­å®š */}
      <div className="settings-section">
        <h3>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«é¸æŠ</h3>

        {/* Local AI */}
        <div className="radio-group">
          <label>
            <input
              type="radio"
              name="ai-mode"
              value="ollama"
              checked={config.ai.mode === 'ollama'}
              onChange={(e) => handleInputChange('ai', 'mode', e.target.value)}
              disabled={!ollamaAvailable || llmModels.length === 0}
            />
            ğŸ  Local AI
          </label>

          {ollamaAvailable && llmModels.length > 0 ? (
            <select
              value={config.ai.ollama_model || ''}
              onChange={(e) => handleInputChange('ai', 'ollama_model', e.target.value)}
              disabled={config.ai.mode !== 'ollama'}
            >
              {!config.ai.ollama_model && <option value="">ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ...</option>}
              {llmModels.map(model => (
                <option 
                  key={model.name} 
                  value={model.name}
                  disabled={!model.capable}
                >
                  {model.name} ({model.size}GB) {model.capable ? 'âœ…' : 'âš ï¸ èƒ½åŠ›ä¸è¶³'}
                </option>
              ))}
            </select>
          ) : (
            <select disabled>
              <option>âŒ Ollamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>
            </select>
          )}
        </div>

        {/* API */}
        <div className="radio-group">
          <label>
            <input
              type="radio"
              name="ai-mode"
              value="api"
              checked={config.ai.mode === 'api'}
              onChange={(e) => handleInputChange('ai', 'mode', e.target.value)}
            />
            ğŸŒ API
          </label>
          <input
            type="text"
            value={config.ai.api_model || ''}
            onChange={(e) => handleInputChange('ai', 'api_model', e.target.value)}
            placeholder="gpt-4o-mini"
            disabled={config.ai.mode !== 'api'}
          />
          <small>GPT-4o-miniä»¥ä¸Šã‚’æ¨å¥¨</small>
        </div>

        <div className="form-group">
          <label>ğŸ”‘ APIã‚­ãƒ¼:</label>
          <input
            type="password"
            value={config.ai.api_key || ''}
            onChange={(e) => handleInputChange('ai', 'api_key', e.target.value)}
            disabled={config.ai.mode !== 'api'}
            placeholder={config.ai.mode === 'api' ? 'sk-...' : 'Local AIã§ã¯ä¸è¦'}
          />
        </div>

        {/* æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆAPIãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰ */}
        {config.ai.mode === 'api' && (
          <button onClick={handleTestAI} disabled={testingAI}>
            {testingAI ? 'ç¢ºèªä¸­...' : 'ğŸ” APIæ¥ç¶šç¢ºèª'}
          </button>
        )}

        {/* Ollamaãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯æ¥ç¶šæ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
        {config.ai.mode === 'ollama' && ollamaAvailable && (
          <div className="success-box">
            âœ… Ollamaæ¥ç¶šæ¸ˆã¿ ğŸ¦™
          </div>
        )}
      </div>

      {/* Refinerè¨­å®š */}
      <div className="settings-section">
        <h3>Refinerï¼ˆä»•ä¸Šã’ï¼‰ãƒ¢ãƒ‡ãƒ«</h3>
        
        <label className="toggle-label">
          <input 
            type="checkbox"
            checked={customRefiner}
            onChange={(e) => handleCustomRefinerToggle(e.target.checked)}
          />
          <strong>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨ã¯åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹</strong>
        </label>
        <small className="hint-text">
          åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šä¸‹ä½ã®AIã‚’æŒ‡å®šã™ã‚‹ã¨ç²¾åº¦ãŒä¸‹ãŒã‚Šã¾ã™ã€‚<br/>
          Criticãƒ¢ãƒ‡ãƒ«ã¯å¸¸ã«åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚‚ã®ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¤‰æ›´ä¸å¯ï¼‰
        </small>

        {!customRefiner ? (
          // è¿½å¾“ãƒ¢ãƒ¼ãƒ‰ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨è¡¨ç¤ºï¼‰
          <div className="readonly-refiner">
            <p className="info-text">ğŸ“Œ åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™</p>
            <div className="info-box">
              <p><strong>ãƒ¢ãƒ¼ãƒ‰:</strong> {config.ai.mode === 'api' ? 'ğŸŒ API' : 'ğŸ  Local AI'}</p>
              <p><strong>ãƒ¢ãƒ‡ãƒ«:</strong> {getCurrentModel()}</p>
            </div>
          </div>
        ) : (
          // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãƒ¢ãƒ¼ãƒ‰
          <div className="custom-config">
            <div className="warning-box">
            </div>

            {/* Refiner Local AI */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="refiner-mode"
                  value="ollama"
                  checked={config.ai.refiner_mode === 'ollama'}
                  onChange={(e) => handleInputChange('ai', 'refiner_mode', e.target.value)}
                  disabled={!ollamaAvailable || llmModels.length === 0}
                />
                ğŸ  Local AI
              </label>
              
              {ollamaAvailable && llmModels.length > 0 ? (
                <select
                  value={config.ai.refiner_model || ''}
                  onChange={(e) => handleInputChange('ai', 'refiner_model', e.target.value)}
                  disabled={config.ai.refiner_mode !== 'ollama'}
                >
                  {!config.ai.refiner_model && <option value="">ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ...</option>}
                  {llmModels.map(model => (
                    <option 
                      key={model.name} 
                      value={model.name}
                      disabled={!model.capable}
                    >
                      {model.name} ({model.size}GB) {model.capable ? 'âœ…' : 'âš ï¸'}
                    </option>
                  ))}
                </select>
              ) : (
                <select disabled>
                  <option>âŒ Ollamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>
                </select>
              )}
            </div>

            {/* Refiner API */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="refiner-mode"
                  value="api"
                  checked={config.ai.refiner_mode === 'api'}
                  onChange={(e) => handleInputChange('ai', 'refiner_mode', e.target.value)}
                />
                ğŸŒ API
              </label>
              <input
                type="text"
                value={config.ai.refiner_model || ''}
                onChange={(e) => handleInputChange('ai', 'refiner_model', e.target.value)}
                placeholder="claude-sonnet-4-20250514ï¼ˆä¸Šä½ãƒ¢ãƒ‡ãƒ«æ¨å¥¨ï¼‰"
                disabled={config.ai.refiner_mode !== 'api'}
              />
            </div>

            {config.ai.refiner_mode === 'api' && (
              <div className="form-group">
                <label>ğŸ”‘ APIã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:</label>
                <input
                  type="password"
                  value={config.ai.refiner_api_key || ''}
                  onChange={(e) => handleInputChange('ai', 'refiner_api_key', e.target.value)}
                  placeholder="ç©ºæ¬„ãªã‚‰åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚­ãƒ¼ã‚’ä½¿ç”¨"
                />
              </div>
            )}

            {/* Refineræ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆAPIãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰ */}
            {config.ai.refiner_mode === 'api' && (
              <button onClick={handleTestRefiner} disabled={testingRefiner}>
                {testingRefiner ? 'ç¢ºèªä¸­...' : 'ğŸ” Refineræ¥ç¶šç¢ºèª'}
              </button>
            )}

            {/* Ollamaãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯æ¥ç¶šæ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
            {config.ai.refiner_mode === 'ollama' && ollamaAvailable && (
              <div className="success-box">
                âœ… Ollamaæ¥ç¶šæ¸ˆã¿ ğŸ¦™
              </div>
            )}
          </div>
        )}
      </div>

      {/* å›³è¡¨è§£æ */}
      <div className="settings-section">
        <h3>ğŸ–¼ï¸ å›³è¡¨è§£æãƒ¢ãƒ‡ãƒ«</h3>
        
        {ollamaAvailable && visionModels.length > 0 ? (
          <div className="form-group">
            <select
              value={config.ai.vision_model || ''}
              onChange={(e) => handleInputChange('ai', 'vision_model', e.target.value)}
            >
              {visionModels.map(model => (
                <option key={model.name} value={model.name}>
                  {model.name} ({model.size}GB)
                </option>
              ))}
            </select>
            <small>å›³è¡¨ã®è§£æã«ä½¿ç”¨</small>
          </div>
        ) : (
          <div className="warning-box">
            âš ï¸ Visionãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚
            <code>ollama pull granite3.2-vision</code> ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚
          </div>
        )}
      </div>

      {/* ä¿å­˜ãƒœã‚¿ãƒ³ */}
      <div className="actions">
        <button onClick={handleSave} disabled={loading} className="btn-primary">
          {loading ? 'ä¿å­˜ä¸­...' : ' è¨­å®šã‚’ä¿å­˜'}
        </button>
      </div>
    </div>
  );
};