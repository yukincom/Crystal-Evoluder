import React, { useState, useEffect } from 'react';
import { getConfig, saveConfig, testAIConnection } from '../api/client';
import type { Config } from '../types';
import './AISettings.css';

interface OllamaModel {
  name: string;
  size: number;
  capable: boolean;
  is_vision: boolean;
}

export const AISettings: React.FC = () => {
  const [config, setConfig] = useState<Config | null>(null);
  const [loading, setLoading] = useState(false);
  const [testingAI, setTestingAI] = useState(false);
  const [testingRefiner, setTestingRefiner] = useState(false); // Refinerç”¨  
  const [customRefiner, setCustomRefiner] = useState(false);

    // Ollamaãƒ¢ãƒ‡ãƒ«ä¸€è¦§
  const [ollamaModels, setOllamaModels] = useState<OllamaModel[]>([]);
  const [ollamaAvailable, setOllamaAvailable] = useState(false);
  const [loadingModels, setLoadingModels] = useState(false);

  useEffect(() => {
    loadConfig();
    loadOllamaModels(); // Ollamaãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—    
  }, []);

  useEffect(() => {
    // configãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã‚‰ã€refiner_modeãŒnullã§ãªã‘ã‚Œã°ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã¨åˆ¤å®š
    if (config && config.ai.refiner_mode !== null) {
      setCustomRefiner(true);
    }
  }, [config]);

  const loadConfig = async () => {
    try {
      const data = await getConfig();
      setConfig(data);
    } catch (error) {
      console.error('Failed to load config:', error);
    }
  };

  const loadOllamaModels = async () => {
    setLoadingModels(true);
    try {
      const response = await fetch('http://localhost:8000/config/ollama/models');
      const data = await response.json();
      
      if (data.available) {
        setOllamaAvailable(true);
        setOllamaModels(data.models);
      } else {
        setOllamaAvailable(false);
        setOllamaModels([]);
      }
    } catch (error) {
      console.error('Failed to load Ollama models:', error);
      setOllamaAvailable(false);
    } finally {
      setLoadingModels(false);
    }
  };

  const handleSave = async () => {
    if (!config) return;
    setLoading(true);
    try {
      await saveConfig(config);
      alert('è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ');
    } catch (error) {
      alert('ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ');
    } finally {
      setLoading(false);
    }
  };

  const handleTestAI = async () => {
    if (!config) return;
    setTestingAI(true);
    try {
      const result = await testAIConnection(config.ai);
      alert(result.message || 'âœ… æ¥ç¶šæˆåŠŸï¼');
    } catch (error: any) {
      alert(`âŒ æ¥ç¶šå¤±æ•—: ${error.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
    } finally {
      setTestingAI(false);
    }
  };


  const handleTestRefiner = async () => {
    if (!config) return;
    setTestingRefiner(true);
    try {
      // Refinerã®è¨­å®šã‚’æ§‹ç¯‰
      const refinerConfig = {
        mode: config.ai.refiner_mode || config.ai.mode,
        api_key: config.ai.refiner_api_key || config.ai.api_key,
        ollama_url: config.ai.refiner_ollama_url || config.ai.ollama_url,
        llm_model: config.ai.refiner_model || config.ai.llm_model,
      };
      
      const result = await testAIConnection(refinerConfig);
      alert(result.message || 'âœ… Refineræ¥ç¶šæˆåŠŸï¼');
    } catch (error: any) {
      alert(`âŒ Refineræ¥ç¶šå¤±æ•—: ${error.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
    } finally {
      setTestingRefiner(false);
    }
  };

  const handleInputChange = (section: keyof Config, field: string, value: any) => {
    if (!config) return;
        // ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿æ™‚ã®ç‰¹åˆ¥å‡¦ç†
    if (section === 'ai' && field === 'mode') {
      setConfig({
        ...config,
        ai: {
          ...config.ai,
          mode: value,
          // Ollamaã«åˆ‡ã‚Šæ›¿ãˆã‚‹å ´åˆã€åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Œã°ãã‚Œã‚’è¨­å®š
          llm_model: value === 'ollama' && llmModels.length > 0 
            ? llmModels.find(m => m.capable)?.name || llmModels[0].name
            : value === 'api' && config.ai.mode === 'ollama'
              ? 'gpt-4o-mini' // Ollamaã‹ã‚‰æˆ»ã™å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
              : config.ai.llm_model
        }
      });
    } else {

    setConfig({
      ...config,
      [section]: {
        ...config[section],
        [field]: value
        }
      });
    }
  };

  const handleCustomRefinerToggle = (enabled: boolean) => {
    setCustomRefiner(enabled);

    if (!config) return;
    
    if (enabled) {
      // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’æœ‰åŠ¹åŒ–ï¼šãƒ¡ã‚¤ãƒ³ã®è¨­å®šã‚’ã‚³ãƒ”ãƒ¼
      setConfig({
        ...config,
        ai: {
          ...config.ai,
          refiner_mode: config.ai.mode,
          refiner_model: config.ai.llm_model,
          refiner_api_key: config.ai.api_key,
          refiner_ollama_url: config.ai.ollama_url
        }
      });
    } else {
      // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’ç„¡åŠ¹åŒ–ï¼šnullã«æˆ»ã™ï¼ˆãƒ¡ã‚¤ãƒ³ã«è¿½å¾“ï¼‰
      setConfig({
        ...config,
        ai: {
          ...config.ai,
          refiner_mode: null,
          refiner_model: null,
          refiner_api_key: null,
          refiner_ollama_url: null
        }
      });
    }
  };
  // LLMç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆVisionã‚’é™¤å¤–ï¼‰
  const llmModels = ollamaModels.filter(m => !m.is_vision);
  
  // Visionç”¨ãƒ¢ãƒ‡ãƒ«
  const visionModels = ollamaModels.filter(m => m.is_vision);
    
  if (!config) return <div>Loading...</div>;

  return (
    <div className="ai-settings">
      <h2>AI è¨­å®š</h2>
      {/* Ollamaæ¥ç¶šçŠ¶æ…‹ */}
      {loadingModels && (
        <div className="info-box">â³ Ollamaãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...</div>
      )}
      {!loadingModels && !ollamaAvailable && (
        <div className="warning-box">
          âš ï¸ OllamaãŒæ¥ç¶šã§ãã¾ã›ã‚“ã€‚Local AIãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€Ollamaã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
          <button onClick={loadOllamaModels} className="btn-small">ğŸ”„ å†èª­è¾¼</button>
        </div>
      )}
      {/* åŸºæœ¬ãƒ¢ãƒ‡ãƒ«è¨­å®š */}
      <div className="settings-section">
        <h3>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«é¸æŠ</h3>
        {/* Local AI */}
        <div className="radio-group">
          <label>
            <input
              type="radio"
              name="ai-mode"
              value="ollama"
              checked={config.ai.mode === 'ollama'}
              onChange={(e) => handleInputChange('ai', 'mode', e.target.value)}
              disabled={!ollamaAvailable}
            />
            ğŸ  Local_AI
          </label>

          {ollamaAvailable && llmModels.length > 0 ? (
            <select
              value={config.ai.llm_model}
              onChange={(e) => handleInputChange('ai', 'llm_model', e.target.value)}
              disabled={config.ai.mode !== 'ollama'}
            >
              {llmModels.map(model => (
                <option 
                  key={model.name} 
                  value={model.name}
                  disabled={!model.capable}
                >
                  {model.name} ({model.size}GB) {model.capable ? 'âœ…' : 'âš ï¸ èƒ½åŠ›ä¸è¶³'}
                </option>
              ))}
            </select>
          ) : (
            <select disabled>
              <option>âŒ Ollamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>
            </select>
          )}
        </div>
          {/* API */}
        <div className="radio-group">
          <label>
            <input
              type="radio"
              name="ai-mode"
              value="api"
              checked={config.ai.mode === 'api'}
              onChange={(e) => handleInputChange('ai', 'mode', e.target.value)}
            />

            ğŸŒ API_AI
          </label>
          <input
            type="text"
            value={config.ai.llm_model}
            onChange={(e) => handleInputChange('ai', 'llm_model', e.target.value)}
            placeholder="gpt-4o-mini"
            disabled={config.ai.mode !== 'api'}
          />
          <small>GPT-4o-miniä»¥ä¸Šã‚’æ¨å¥¨</small>
        </div>

        <div className="form-group">
          <label>ğŸ”‘ APIã‚­ãƒ¼:</label>
          <input
            type="password"
            value={config.ai.api_key}
            onChange={(e) => handleInputChange('ai', 'api_key', e.target.value)}
            disabled={config.ai.mode !== 'api'}
            placeholder={config.ai.mode === 'api' ? 'sk-...' : 'Local AIã§ã¯ä¸è¦'}
          />
        </div>
        {/* æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆAPIãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰ */}
        {config.ai.mode === 'api' && (
        <button onClick={handleTestAI} disabled={testingAI}>
          {testingAI ? 'ç¢ºèªä¸­...' : 'ğŸ” API æ¥ç¶šç¢ºèª'}
        </button>
        )}
                {/* Ollamaãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯æ¥ç¶šæ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
        {config.ai.mode === 'ollama' && ollamaAvailable && (
          <div className="success-box">
            âœ… Ollama æ¥ç¶šæ¸ˆã¿ ğŸ¦™ğŸ¦™ğŸ¦™
          </div>
        )}
      
      </div>
        {/* Refinerè¨­å®š */}
      <div className="settings-section">
        <h3>Refinerï¼ˆä»•ä¸Šã’ï¼‰ãƒ¢ãƒ‡ãƒ«</h3>
         
        <label className="toggle-label">
          <input 
            type="checkbox"
            checked={customRefiner}
            onChange={(e) => handleCustomRefinerToggle(e.target.checked)}
          />ãƒ¢ãƒ‡ãƒ«å¤‰æ›´<small>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šä¸‹ä½ã®ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ãªã„ã§ãã ã•ã„ã€‚</small>
        </label>

        {!customRefiner ? (
          // è¿½å¾“ãƒ¢ãƒ¼ãƒ‰
          <div className="readonly-info">
            <p>ğŸ“Œ <strong>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜AIã‚’åˆ©ç”¨</strong></p>

          </div>
        ) : (
          
          // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãƒ¢ãƒ¼ãƒ‰
          <div className="custom-config">
            {/* Refiner Local AI */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="refiner-mode"
                  value="ollama"
                  checked={config.ai.refiner_mode === 'ollama'}
                  onChange={(e) => handleInputChange('ai', 'refiner_mode', e.target.value)}
                  disabled={!ollamaAvailable}                  
                />
              ğŸ  Local AI
              </label>
              {ollamaAvailable && llmModels.length > 0 ? (
                <select
                  value={config.ai.refiner_model || config.ai.llm_model}
                  onChange={(e) => handleInputChange('ai', 'refiner_model', e.target.value)}
                  disabled={config.ai.refiner_mode !== 'ollama'}
                >
                  {llmModels.map(model => (
                    <option 
                      key={model.name} 
                      value={model.name}
                      disabled={!model.capable}
                    >
                      {model.name} ({model.size}GB) {model.capable ? 'âœ…' : 'âš ï¸'}
                    </option>
                  ))}
                </select>
              ) : (
                <select disabled>
                  <option>âŒ Ollamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>
                </select>
              )}
            </div>
          {/* Refiner API */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="refiner-mode"
                  value="api"
                  checked={config.ai.refiner_mode === 'api'}
                  onChange={(e) => handleInputChange('ai', 'refiner_mode', e.target.value)}
                />
                ğŸŒ API
              </label>
              <input
                type="text"
                value={config.ai.refiner_model || config.ai.llm_model}
                onChange={(e) => handleInputChange('ai', 'refiner_model', e.target.value)}
                placeholder="gpt-4oï¼ˆä¸Šä½ãƒ¢ãƒ‡ãƒ«æ¨å¥¨ï¼‰"
                disabled={config.ai.refiner_mode !== 'api'}
              />
            </div>

            {config.ai.refiner_mode === 'api' && (
              <div className="form-group">
                <label>ğŸ”‘ APIã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:</label>
                <input
                  type="password"
                  value={config.ai.refiner_api_key || ''}
                  onChange={(e) => handleInputChange('ai', 'refiner_api_key', e.target.value)}
                  placeholder="ç©ºæ¬„ãªã‚‰åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚­ãƒ¼ã‚’ä½¿ç”¨"
                />
              </div>

            )} 

        {/* æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆAPIãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰ */}
        {config.ai.refiner_mode === 'api' && (            
        <button onClick={handleTestRefiner} disabled={testingRefiner}>
          {testingRefiner ? 'ç¢ºèªä¸­...' : 'ğŸ” APIæ¥ç¶šç¢ºèª'}
        </button>
        )}

        {/* Ollamaãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯æ¥ç¶šæ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
        {config.ai.refiner_mode === 'ollama' && ollamaAvailable && (
          <div className="success-box">
            âœ… Ollama æ¥ç¶šæ¸ˆã¿ ğŸ¦™ğŸ¦™ğŸ¦™
          </div>
        )}
        </div>)} 
</div>      

      <div className="settings-section">
        <h3>å›³è¡¨è§£æãƒ¢ãƒ‡ãƒ«</h3>

        {ollamaAvailable && visionModels.length > 0 ? (
          <div className="form-group">
            <select
              value={config.ai.vision_model}
              onChange={(e) => handleInputChange('ai', 'vision_model', e.target.value)}
            >
              {visionModels.map(model => (
                <option key={model.name} value={model.name}>
                  {model.name} ({model.size}GB)
                </option>
              ))}
            </select>
          </div>
        ) : (
          <div className="warning-box">
            âš ï¸ Visionãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚
            <code>ollama pull granite3.2-vision</code> ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚
          </div>
        )}
      </div>


      <div className="actions">
        <button onClick={handleSave} disabled={loading}>
          {loading ? 'ä¿å­˜ä¸­...' : 'ä¿å­˜'}
        </button>
      </div>
    </div>
  );
};