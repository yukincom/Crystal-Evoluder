import React, { useState, useEffect } from 'react';
import { getConfig, saveConfig, testAIConnection } from '../api/client';
import type { Config } from '../types';
import './AISettings.css';

interface OllamaModel {
  name: string;
  size: number;
  capable: boolean;
  is_vision: boolean;
  recommended_for_base?: boolean;      // Baseç”¨æ¨å¥¨ãƒ•ãƒ©ã‚°
  recommended_for_quality?: boolean;   // Qualityç”¨æ¨å¥¨ãƒ•ãƒ©ã‚°
}

export const AISettings: React.FC = () => {
  const [config, setConfig] = useState<Config | null>(null);
  const [loading, setLoading] = useState(false);
  const [testingAI, setTestingAI] = useState(false);
  const [testingQualityCheck, setTestingQualityCheck] = useState(false);
  const [testingRefiner, setTestingRefiner] = useState(false);
  const [customRefiner, setCustomRefiner] = useState(false);
  const [customQualityCheck, setCustomQualityCheck] = useState(false);

  // Ollamaãƒ¢ãƒ‡ãƒ«ä¸€è¦§
  const [ollamaModels, setOllamaModels] = useState<OllamaModel[]>([]);
  const [ollamaAvailable, setOllamaAvailable] = useState(false);
  const [loadingModels, setLoadingModels] = useState(false);

  // LLMç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆVisionã‚’é™¤å¤–ï¼‰
  const llmModels = ollamaModels.filter(m => !m.is_vision);

  useEffect(() => {
    loadOllamaModels();
    loadConfig();
  }, []);

  useEffect(() => {
    if (config) {
      // Refinerã®ã‚«ã‚¹ã‚¿ãƒ åˆ¤å®š
      setCustomRefiner(config.ai.refiner_mode !== null);
      
      // å“è³ªãƒã‚§ãƒƒã‚¯ã®ã‚«ã‚¹ã‚¿ãƒ åˆ¤å®š
      setCustomQualityCheck(config.ai.quality_mode !== null);
    }
  }, [config]);

  useEffect(() => {
    // Ollamaãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¾Œã€configãŒã‚ã‚Œã°æ¤œè¨¼
    if (!config || !ollamaModels.length) return;

    if (config.ai.mode === 'ollama') {
      const currentModel = config.ai.ollama_model;
      
      if (!currentModel || currentModel === '') {
        const firstValidModel = llmModels.find(m => m.capable);
        if (firstValidModel) {
          setConfig({
            ...config,
            ai: {
              ...config.ai,
              ollama_model: firstValidModel.name
            }
          });
          console.log('âœ… Auto-selected Ollama model:', firstValidModel.name);
        }
      }
    }
  }, [config, ollamaModels, llmModels]);

  const loadConfig = async () => {
    try {
      const data = await getConfig();
      setConfig(data);
    } catch (error) {
      console.error('Failed to load config:', error);
    }
  };

  const loadOllamaModels = async () => {
    setLoadingModels(true);
    try {
      const response = await fetch('http://localhost:8000/config/ollama/models');
      const data = await response.json();
      
      if (data.available) {
        setOllamaAvailable(true);
        setOllamaModels(data.models);
      } else {
        setOllamaAvailable(false);
        setOllamaModels([]);
      }
    } catch (error) {
      console.error('Failed to load Ollama models:', error);
      setOllamaAvailable(false);
    } finally {
      setLoadingModels(false);
    }
  };

  const handleSave = async () => {
    if (!config) return;
    setLoading(true);
    try {
      await saveConfig(config);
      alert('âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ');
    } catch (error) {
      alert('âŒ ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ');
    } finally {
      setLoading(false);
    }
  };

  const handleTestAI = async () => {
    if (!config) return;
    setTestingAI(true);
    try {
      const testConfig = {
        mode: config.ai.mode,
        api_key: config.ai.api_key,
        ollama_url: config.ai.ollama_url,
        api_model: config.ai.api_model,      
        ollama_model: config.ai.ollama_model, 
      };

      const result = await testAIConnection(testConfig);
      alert(result.message || 'âœ… æ¥ç¶šæˆåŠŸï¼');
    } catch (error: any) {
      alert(`âŒ æ¥ç¶šå¤±æ•—: ${error.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
    } finally {
      setTestingAI(false);
    }
  };

  const handleTestQualityCheck = async () => {
    if (!config) return;
    setTestingQualityCheck(true);

    try {
      const qualityCheckConfig = {
        mode: config.ai.quality_mode || config.ai.mode,
        api_key: config.ai.quality_check_api_key || config.ai.api_key,
        ollama_url: config.ai.quality_check_ollama_url || config.ai.ollama_url,
        api_model: config.ai.quality_check_api_model || config.ai.api_model,
        ollama_model: config.ai.quality_check_ollama_model || config.ai.ollama_model,
      };

      const result = await testAIConnection(qualityCheckConfig);
      alert(result.message || 'âœ… å“è³ªãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«æ¥ç¶šæˆåŠŸ');
    } catch (error: any) {
      alert(`âŒ å“è³ªãƒã‚§ãƒƒã‚¯æ¥ç¶šå¤±æ•—: ${error.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
    } finally {
      setTestingQualityCheck(false);
    }
  };

  const handleTestRefiner = async () => {
    if (!config) return;
    setTestingRefiner(true);
    try {
      const currentModel = config.ai.mode === 'api' 
        ? config.ai.api_model 
        : config.ai.ollama_model;
      
      const refinerConfig = {
        mode: config.ai.refiner_mode || config.ai.mode,
        api_key: config.ai.refiner_api_key || config.ai.api_key,
        ollama_url: config.ai.refiner_ollama_url || config.ai.ollama_url,
        api_model: config.ai.refiner_api_model || currentModel,
        ollama_model: config.ai.refiner_ollama_model || currentModel,
      };
      
      const result = await testAIConnection(refinerConfig);
      alert(result.message || 'âœ… Refineræ¥ç¶šæˆåŠŸï¼');
    } catch (error: any) {
      alert(`âŒ Refineræ¥ç¶šå¤±æ•—: ${error.message || 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`);
    } finally {
      setTestingRefiner(false);
    }
  };

  const handleInputChange = (section: keyof Config, field: string, value: any) => {
    if (!config) return;
    
    setConfig({
      ...config,
      [section]: {
        ...config[section],
        [field]: value
      }
    });
  };

  const getCurrentModel = (): string => {
    if (!config) return '(æœªè¨­å®š)';
    return config.ai.mode === 'api' 
      ? config.ai.api_model || '(æœªæŒ‡å®š)' 
      : config.ai.ollama_model || '(æœªæŒ‡å®š)';
  };

  const handleCustomQualityCheckToggle = (enabled: boolean) => {
    if (!config) return;
    
    setCustomQualityCheck(enabled);
    
    if (enabled) {
      // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’æœ‰åŠ¹åŒ–
      setConfig({
        ...config,
        ai: {
          ...config.ai,
          quality_check_api_model: config.ai.mode === 'api' ? 'gpt-4o-mini' : config.ai.quality_check_api_model,
          quality_check_ollama_model: config.ai.mode === 'ollama' ? (llmModels.find(m => m.capable)?.name || '') : config.ai.quality_check_ollama_model
         }
      });
    } else {
      // ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚’ç„¡åŠ¹åŒ–
      setConfig({
        ...config,
        ai: {
          ...config.ai,
          quality_mode: null,
          quality_check_api_model: undefined,
          quality_check_ollama_model: undefined,
          quality_check_api_key: null,
          quality_check_ollama_url: null
        }
      });
    }
  };

  const handleCustomRefinerToggle = (enabled: boolean) => {
    if (!config) return;
    
    setCustomRefiner(enabled);
    
    if (enabled) {
      let currentModel = config.ai.mode === 'api' 
        ? config.ai.api_model 
        : config.ai.ollama_model;
      
      if (config.ai.mode === 'ollama') {
        const isValidModel = llmModels.some(m => m.name === currentModel && m.capable);
        
        if (!isValidModel || !currentModel) {
          const firstValidModel = llmModels.find(m => m.capable);
          currentModel = firstValidModel?.name || '';
        }
      }
      
      if (config.ai.mode === 'api' && !currentModel) {
        currentModel = 'gpt-4o-mini';
      }

      setConfig({
        ...config,
        ai: {
          ...config.ai,
          refiner_mode: config.ai.mode,
          refiner_api_model: config.ai.mode === 'api' ? config.ai.api_model : config.ai.refiner_api_model,
          refiner_ollama_model: config.ai.mode === 'ollama' ? config.ai.ollama_model : config.ai.refiner_ollama_model
        }
      });
    } else {
      setConfig({
        ...config,
        ai: {
          ...config.ai,
          refiner_mode: null,
          refiner_api_model: undefined,
          refiner_ollama_model: undefined,
          refiner_api_key: null,
          refiner_ollama_url: null
        }
      });
    }
  };

  if (!config) return <div className="ai-settings">Loading...</div>;

  return (
    <div className="ai-settings">
      <h2>AI è¨­å®š</h2>

      {/* Ollamaæ¥ç¶šçŠ¶æ…‹ */}
      {loadingModels && (
        <div className="info-box">â³ Ollamaãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...</div>
      )}
      
      {!loadingModels && !ollamaAvailable && (
        <div className="warning-box">
          âš ï¸ OllamaãŒæ¥ç¶šã§ãã¾ã›ã‚“ã€‚Local AIãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€Ollamaã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
          <button onClick={loadOllamaModels} className="btn-secondary" style={{marginLeft: '12px'}}>ğŸ”„ å†èª­è¾¼</button>
        </div>
      )}

      {/* åŸºæœ¬ãƒ¢ãƒ‡ãƒ«è¨­å®š */}
      <div className="settings-section">
        <h3>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«é¸æŠ</h3>
        <small style={{display: 'block', marginBottom: '12px', color: '#6b7280'}}>
          æ¨å¥¨ï¼š14Bã€œ32Bã‚¯ãƒ©ã‚¹ï¼ˆãƒˆãƒªãƒ—ãƒ¬ãƒƒãƒˆæŠ½å‡ºç”¨ï¼‰
        </small>

        {/* Local AI */}
        <div className="radio-group">
          <label>
            <input
              type="radio"
              name="ai-mode"
              value="ollama"
              checked={config.ai.mode === 'ollama'}
              onChange={(e) => handleInputChange('ai', 'mode', e.target.value)}
              disabled={!ollamaAvailable || llmModels.length === 0}
            />
            ğŸ  Local AI
          </label>

          {ollamaAvailable && llmModels.length > 0 ? (
            <select
              value={config.ai.ollama_model || ''}
              onChange={(e) => handleInputChange('ai', 'ollama_model', e.target.value)}
              disabled={config.ai.mode !== 'ollama'}
            >
              {!config.ai.ollama_model && <option value="">ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ...</option>}
              {llmModels.map(model => {
              // Baseç”¨ã®è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯
              const isRecommended = model.recommended_for_base;
              const displayText = isRecommended 
                ? `${model.name} (${model.size}GB) âœ… æ¨å¥¨`
                : `${model.name} (${model.size}GB) âš ï¸ æ€§èƒ½ä¸è¶³`;
    
              return (
                <option 
                  key={model.name} 
                  value={model.name}
                  disabled={!model.recommended_for_base}
                >
                  {displayText}
                </option>
                  );
              })}
            </select>
          ) : (
            <select disabled>
              <option>âŒ Ollamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>
            </select>
          )}
        </div>

        {/* API */}
        <div className="radio-group">
          <label>
            <input
              type="radio"
              name="ai-mode"
              value="api"
              checked={config.ai.mode === 'api'}
              onChange={(e) => handleInputChange('ai', 'mode', e.target.value)}
            />
            ğŸŒ API
          </label>
          <input
            type="text"
            value={config.ai.api_model || ''}
            onChange={(e) => handleInputChange('ai', 'api_model', e.target.value)}
            placeholder="gpt-4o-mini"
            disabled={config.ai.mode !== 'api'}
          />
        </div>

        <div className="form-group">
          <label>ğŸ”‘ APIã‚­ãƒ¼:</label>
          <input
            type="password"
            value={config.ai.api_key || ''}
            onChange={(e) => handleInputChange('ai', 'api_key', e.target.value)}
            disabled={config.ai.mode !== 'api'}
            placeholder={config.ai.mode === 'api' ? 'sk-...' : 'Local AIã§ã¯ä¸è¦'}
          />
        </div>

        {/* æ¥ç¶šãƒ†ã‚¹ãƒˆ */}
        {config.ai.mode === 'api' && (
          <div className="test-button-row">
            <button onClick={handleTestAI} disabled={testingAI}>
              {testingAI ? 'ç¢ºèªä¸­...' : 'ğŸ” APIæ¥ç¶šç¢ºèª'}
            </button>
          </div>
        )}

        {config.ai.mode === 'ollama' && ollamaAvailable && (
          <div className="success-box">
            âœ… Ollamaæ¥ç¶šæ¸ˆã¿ ğŸ¦™
          </div>
        )}
      </div>

      {/* å“è³ªãƒã‚§ãƒƒã‚¯å°‚ç”¨ãƒ¢ãƒ‡ãƒ«è¨­å®š */}
      <div className="settings-section">
        <h3>å“è³ªãƒã‚§ãƒƒã‚¯å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨å¥¨ï¼šè»½é‡ãƒ¢ãƒ‡ãƒ«ï¼‰</h3>
        
        <label className="toggle-label">
          <input 
            type="checkbox"
            checked={customQualityCheck}
            onChange={(e) => handleCustomQualityCheckToggle(e.target.checked)}
          />
          <strong>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨ã¯åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹</strong>
        </label>
        <small className="hint-text">
          ğŸ’¡ å“è³ªãƒã‚§ãƒƒã‚¯ã¯7Bã€œ8Bã‚¯ãƒ©ã‚¹ã®è»½é‡ãƒ¢ãƒ‡ãƒ«ã§ååˆ†ã§ã™ã€‚<br/>
          æœªè¨­å®šã®å ´åˆã¯åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚‚ã®ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
        </small>

        {!customQualityCheck ? (
          <div className="readonly-refiner">
            <p className="info-text">ğŸ“Œ åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™</p>
            <div className="info-box">
              <p><strong>ãƒ¢ãƒ¼ãƒ‰:</strong> {config.ai.mode === 'api' ? 'ğŸŒ API' : 'ğŸ  Local AI'}</p>
              <p><strong>ãƒ¢ãƒ‡ãƒ«:</strong> {getCurrentModel()}</p>
            </div>
          </div>
        ) : (
          <div className="custom-config">
            {/* Quality Check Local AI */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="quality-mode"
                  value="ollama"
                  checked={config.ai.quality_mode === 'ollama'}
                  onChange={(e) => handleInputChange('ai', 'quality_mode', e.target.value)}
                  disabled={!ollamaAvailable || llmModels.length === 0}
                />
                ğŸ  Local AI
              </label>

                            {ollamaAvailable && llmModels.length > 0 ? (
                <select
                  value={config.ai.quality_check_ollama_model || ''}
                  onChange={(e) => handleInputChange('ai', 'quality_check_ollama_model', e.target.value)}
                  disabled={config.ai.quality_mode !== 'ollama'}
                >
                  {!config.ai.quality_check_ollama_model && <option value="">ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ...</option>}
                  {llmModels.map(model => {
                    const isRecommended = model.recommended_for_quality;
                    const label = isRecommended 
                      ? `${model.name} (${model.size}GB) âœ… æœ€é©`
                      : `${model.name} (${model.size}GB) âš ï¸ æ€§èƒ½ä¸è¶³`;
                    
                    return (
                      <option 
                        key={model.name} 
                        value={model.name}
                        disabled={!model.capable}
                      >
                        {label}
                      </option>
                    );
                  })}
                </select>
              ) : (
                <select disabled>
                  <option>âŒ Ollamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>
                </select>
              )}
            </div>

            {/* Quality Check API */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="quality-mode"
                  value="api"
                  checked={config.ai.quality_mode === 'api'}
                  onChange={(e) => handleInputChange('ai', 'quality_mode', e.target.value)}
                />
                ğŸŒ API
              </label>
              <input
                type="text"
                value={config.ai.quality_check_api_model || ''}
                onChange={(e) => handleInputChange('ai', 'quality_check_api_model', e.target.value)}
                placeholder="gpt-4o-mini"
                disabled={config.ai.quality_mode !== 'api'}
              />
            </div>

            {config.ai.quality_mode === 'api' && (
              <div className="form-group">
                <label>ğŸ”‘ APIã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:</label>
                <input
                  type="password"
                  value={config.ai.quality_check_api_key || ''}
                  onChange={(e) => handleInputChange('ai', 'quality_check_api_key', e.target.value)}
                  placeholder="ç©ºæ¬„ãªã‚‰åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚­ãƒ¼ã‚’ä½¿ç”¨"
                />
              </div>
            )}

            {config.ai.quality_mode === 'api' && (
              <div className="test-button-row">
                <button onClick={handleTestQualityCheck} disabled={testingQualityCheck}>
                  {testingQualityCheck ? 'ç¢ºèªä¸­...' : 'ğŸ” å“è³ªãƒã‚§ãƒƒã‚¯æ¥ç¶šç¢ºèª'}
                </button>
              </div>
            )}

            {config.ai.quality_mode === 'ollama' && ollamaAvailable && (
              <div className="success-box">
                âœ… Ollamaæ¥ç¶šæ¸ˆã¿ ğŸ¦™
              </div>
            )}
          </div>
        )}
      </div>

      {/* Refinerè¨­å®š */}
      <div className="settings-section">
        <h3>Refinerï¼ˆä»•ä¸Šã’ï¼‰ãƒ¢ãƒ‡ãƒ«</h3>
        
        <label className="toggle-label">
          <input 
            type="checkbox"
            checked={customRefiner}
            onChange={(e) => handleCustomRefinerToggle(e.target.checked)}
          />
          <strong>åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨ã¯åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹</strong>
        </label>
        <small className="hint-text">
          åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šä¸‹ä½ã®AIã‚’æŒ‡å®šã™ã‚‹ã¨ç²¾åº¦ãŒä¸‹ãŒã‚Šã¾ã™ã€‚<br/>
          Criticãƒ¢ãƒ‡ãƒ«ã¯å¸¸ã«ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚‚ã®ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¤‰æ›´ä¸å¯ï¼‰
        </small>

        {!customRefiner ? (
          <div className="readonly-refiner">
            <p className="info-text">ğŸ“Œ åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™</p>
            <div className="info-box">
              <p><strong>ãƒ¢ãƒ¼ãƒ‰:</strong> {config.ai.mode === 'api' ? 'ğŸŒ API' : 'ğŸ  Local AI'}</p>
              <p><strong>ãƒ¢ãƒ‡ãƒ«:</strong> {getCurrentModel()}</p>
            </div>
          </div>
        ) : (
          <div className="custom-config">

            {/* Refiner Local AI */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="refiner-mode"
                  value="ollama"
                  checked={config.ai.refiner_mode === 'ollama'}
                  onChange={(e) => handleInputChange('ai', 'refiner_mode', e.target.value)}
                  disabled={!ollamaAvailable || llmModels.length === 0}
                />
                ğŸ  Local AI
              </label>
              {ollamaAvailable && llmModels.length > 0 ? (
                <select
                  value={config.ai.refiner_ollama_model || ''}
                  onChange={(e) => handleInputChange('ai', 'refiner_ollama_model', e.target.value)}
                  disabled={config.ai.refiner_mode !== 'ollama'}
                >
                  {!config.ai.refiner_ollama_model && <option value="">ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ...</option>}
                  {llmModels.map(model => {
                    const isRecommended = model.recommended_for_base;
                    const label = isRecommended 
                      ? `${model.name} (${model.size}GB) âœ… æ¨å¥¨`
                      : `${model.name} (${model.size}GB) âš ï¸ æ€§èƒ½ä¸è¶³`;
                    
                    return (
                      <option 
                        key={model.name} 
                        value={model.name}
                        disabled={!model.recommended_for_base}
                      >
                        {label}
                      </option>
                    );
                  })}
                </select>
              ) : (
                <select disabled>
                  <option>âŒ Ollamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>
                </select>
              )}
            </div>

            {/* Refiner API */}
            <div className="radio-group">
              <label>
                <input
                  type="radio"
                  name="refiner-mode"
                  value="api"
                  checked={config.ai.refiner_mode === 'api'}
                  onChange={(e) => handleInputChange('ai', 'refiner_mode', e.target.value)}
                />
                ğŸŒ API
              </label>
              <input
                type="text"
                value={config.ai.refiner_api_model || ''}
                onChange={(e) => handleInputChange('ai', 'refiner_api_model', e.target.value)}
                placeholder="gpt-4o-mini"
                disabled={config.ai.refiner_mode !== 'api'}
              />
            </div>

            {config.ai.refiner_mode === 'api' && (
              <div className="form-group">
                <label>ğŸ”‘ APIã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:</label>
                <input
                  type="password"
                  value={config.ai.refiner_api_key || ''}
                  onChange={(e) => handleInputChange('ai', 'refiner_api_key', e.target.value)}
                  placeholder="ç©ºæ¬„ãªã‚‰åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ã‚­ãƒ¼ã‚’ä½¿ç”¨"
                />
              </div>
            )}

            {config.ai.refiner_mode === 'api' && (
              <div className="test-button-row">
                <button onClick={handleTestRefiner} disabled={testingRefiner}>
                  {testingRefiner ? 'ç¢ºèªä¸­...' : 'ğŸ” Refineræ¥ç¶šç¢ºèª'}
                </button>
              </div>
            )}

            {config.ai.refiner_mode === 'ollama' && ollamaAvailable && (
              <div className="success-box">
                âœ… Ollamaæ¥ç¶šæ¸ˆã¿ ğŸ¦™
              </div>
            )}
          </div>
        )}
      </div>

      {/* ä¿å­˜ãƒœã‚¿ãƒ³ */}
      <div className="actions">
        <button onClick={handleSave} disabled={loading}>
          {loading ? 'ä¿å­˜ä¸­...' : 'ğŸ’¾ è¨­å®šã‚’ä¿å­˜'}
        </button>
      </div>
    </div>
  );
};